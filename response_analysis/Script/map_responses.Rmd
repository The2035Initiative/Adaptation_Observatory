# Map

## Load & Wrangle Survey Demographic Data
```{r message=FALSE, warning=FALSE}
library(sf)
library(here)
library(tmap)
library(terra)
library(stars)
library(leaflet)
#library(maptiles)
#library(devtools)
#library(ggspatial)
library(tmaptools)
#library(patchwork)
#library(sfheaders)
library(tidyverse)
#library(osmextract)
#library(tidygeocoder)
library(RColorBrewer)
```


```{r message=FALSE, warning=FALSE}
# load BGD data 
bgd <- read_csv("../results/clean_data/adaptation_observatory_bgd_cleaned_survey_questions_R1.csv",
                show_col_types = FALSE)  %>% 
  filter(complete.cases(location_longitude, location_latitude)) 
  
# group duplicated by phone & ip
bgd_dup <- read_csv("../results/clean_data/adaptation_observatory_bgd_cleaned_duplicate_survey_questions_R1.csv",
                    show_col_types = FALSE) %>% 
  group_by(comp_phone1_try1, ip_address) %>% 
  filter(complete.cases(location_longitude, location_latitude)) 


# load IND data 
ind <- read_csv("../results/clean_data/adaptation_observatory_ind_cleaned_survey_questions_R1.csv",
                show_col_types = FALSE) %>% 
  filter(complete.cases(location_longitude, location_latitude)) 
# group duplicated by phone & ip
ind_dup <- read_csv("../results/clean_data/adaptation_observatory_ind_cleaned_duplicate_survey_questions_R1.csv",
                    show_col_types = FALSE) %>% 
  group_by(comp_phone1_try1, ip_address)%>% 
  filter(complete.cases(location_longitude, location_latitude)) 

# create sf objects
bgd_sf <- bgd %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326") %>% 
  st_make_valid()


ind_sf <- ind %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326") %>% 
  st_make_valid() %>% 
  filter(!is.na(geometry))


bgd_sf_browser <- bgd %>% 
  filter(!is.na(geo_lng) & !is.na(geo_lat)) %>%
  st_as_sf(coords = c("geo_lng", "geo_lat"), crs = "EPSG:4326") %>% 
  st_make_valid()


ind_sf_browser <- ind %>% 
  filter(!is.na(geo_lng) & !is.na(geo_lat)) %>%
  st_as_sf(coords = c("geo_lng", "geo_lat"), crs = "EPSG:4326") %>% 
  st_make_valid()

# for duplicates
bgd_dup_sf <- bgd_dup %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326") %>% 
  st_make_valid() %>% 
  filter(!is.na(geometry))

# for duplicates
ind_dup_sf <- ind_dup %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326") %>% 
  st_make_valid() %>% 
  filter(!is.na(geometry))
```

### Let's remove people outside our AOI
We'll do this using a st_join( .pred = st_intersects) using the shapefiles we used to generate the geo-points

```{r}
# read in the shape files
bgd_shp <- read_stars(here("../data/country_datas/bgd_pd_2020_1km.tif")) %>% 
  st_as_sf(crs = "EPSG:4326") %>% 
  st_make_valid()


ind_shp <- read_stars(here("../data/country_datas/ind_pd_2020_1km.tif")) %>% 
  st_as_sf(crs = "EPSG:4326") %>% 
  st_make_valid()
```


# Join

**Note to self, need to update clean_data with this**
```{r}
# Assuming you have a geometry column named 'geometry' in your data frames bgd and ind
# Extract the bounding box from the geometry column
bgd_bbox <- st_bbox(st_union(bgd_shp$geometry))

# Create bounding box polygons using sf
bgd_polygon <- st_as_sfc(st_bbox(bgd_bbox), crs = 4326) %>% 
  st_as_sf()

# Filter points within the AOI using st_intersection
# reduced down to 2238 from 2247
bgd_aoi <- st_intersection(bgd_sf, bgd_polygon)

# save as csv
st_write(bgd_aoi, 
         here("response_analysis/potential_panelists/bgd_ideal_survey_panelists.csv"),
         layer_options = "GEOMETRY=AS_XY")

# this takes a fat minute
ind_bbox <- st_bbox(st_union(ind_shp$geometry))

# Create bounding box polygons using sf
ind_polygon <- st_as_sfc(st_bbox(ind_bbox), crs = 4326) %>% 
  st_as_sf()

# Filter points within the AOI using st_intersection
# reduced down to 1213 from 1214
ind_aoi <- st_intersection(ind_sf, ind_polygon)

# save as csv
st_write(ind_aoi, 
         here("response_analysis/potential_panelists/ind_ideal_survey_panelists.csv"),
         layer_options = "GEOMETRY=AS_XY")
```


## Geospatial Analysis
For anoynmity purposes, it's best these plots don't render with the IP Addresses
```{r}
tmap_mode('view')

ind_response_map <- ind_aoi %>% 
  dplyr::select(-q_url) %>% 
  tm_shape()  +
  tm_basemap(leaflet::providers$Esri.WorldImagery) +
  tm_bubbles(alpha = 0.2,
             fill = 'ip_address',
             col = 'skyblue',) +
  tm_scalebar(position = c('left', 'bottom')) +
  tm_title("Adaptation Observatory Responses, Bangladesh (2024-4-11)")


tmap_save(ind_response_map,
        filename = here("response_analysis/response_visuals/IND_response_visuals/ind_aoi_map.png"))

ind_response_map
```


```{r}
tmap_mode('view')

bgd_response_map <- bgd_aoi %>% 
  dplyr::select(-q_url) %>% 
  tm_shape() +
  tm_basemap(leaflet::providers$Esri.WorldImagery) +
  tm_bubbles(alpha = 0.2,
             fill = 'ip_address',
             col = 'skyblue',) +
  tm_scalebar(position = c('left', 'bottom')) +
  tm_title("Adaptation Observatory Responses, Bangladesh (2024-4-11)")


tmap_save(bgd_response_map,
        filename = here("response_analysis/response_visuals/BGD_response_visuals/bgd_aoi_map.png"))

bgd_response_map
```

### What's the most number of surveys a single ip address has submitted?
```{r}
# let's check our new column
max(bgd_demos$number_of_surverys_submitted)

max(ind_demos$number_of_surverys_submitted)
```


### Simple Plot with Facebook Targeting
```{r}
# Load in Border Shapefiles
bgd_borders <- st_read(here("geospatial/country_shapefiles/geoBoundaries-BGD-ADM0-all/geoBoundaries-BGD-ADM0_simplified.shp"))

ind_borders <- st_read(here("geospatial/country_shapefiles/geoBoundaries-IND-ADM0-all/geoBoundaries-IND-ADM0_simplified.shp"))

# Import Facebook Point Targeting Data
bgd_fb <- read.csv(here("geospatial/surveying_points/bgd_survey_strat_points_1km_95th.csv"))

ind_fb <- read.csv(here("geospatial/surveying_points/ind_survey_strat_points_1km_95th.csv"))

bgd_fb_sf <- st_as_sf(bgd_fb, coords = c("X", "Y"), crs = 4326)
bgd_fb_sf_buffered <- st_buffer(bgd_fb_sf, dist = units::set_units(1000, "m"))

ind_fb_sf <- st_as_sf(ind_fb, coords = c("X", "Y"), crs = 4326)
ind_fb_sf_buffered <- st_buffer(ind_fb_sf, dist = units::set_units(1000, "m"))


# Drop respondent locations outside of country boundaries
bgd_sf_intersect <- st_intersection(bgd_sf, bgd_borders)
bgd_sf_browser_intersect <- st_intersection(bgd_sf_browser, bgd_borders)

ind_sf_intersect <- st_intersection(ind_sf, ind_borders)
ind_sf_browser_intersect <- st_intersection(ind_sf_browser, ind_borders)


bgd_plt <- ggplot() +
  geom_sf(data = bgd_sf_browser_intersect, aes(fill = "Respondents Browser Location", shape = "Respondents Browser Location"), color = "blue", size = 0.25, alpha = 0.5) + 
  geom_sf(data = bgd_sf_intersect, aes(fill = "Respondents Qualtrics Location", shape = "Respondents Qualtrics Location"), color = "skyblue", size = 0.25, alpha = 0.2) + 
  geom_sf(data = bgd_fb_sf_buffered, aes(fill = "Targeted Points", shape = "Targeted Points"), alpha = 1, color = NA) +
  geom_sf(data = bgd_borders, aes(color = "Bangladesh border", linetype = "Bangladesh border"), size = 4, fill = NA, color = "black") +
  scale_fill_manual(name = "", 
                    values = c("Targeted Points" = "red", 
                               "Respondents Browser Location" = "blue", 
                               "Respondents Qualtrics Location" = "skyblue"),
                    guide = guide_legend(order = 1, nrow = 1)) +
  scale_shape_manual(name = "", 
                     values = c("Targeted Points" = 21, 
                                "Respondents Browser Location" = 21, 
                                "Respondents Qualtrics Location" = 24),
                     guide = guide_legend(order = 1, nrow = 1)) +
  scale_linetype_manual(name = "", values = c("Bangladesh border" = "solid"),
                        guide = guide_legend(order = 2, nrow = 1)) +

  labs(
    title = "Bangladesh R1 Spatial Targeting"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom", 
    legend.box = "vertical", 
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.text = element_text(size = 9),
    legend.spacing.x = unit(0.25, 'cm'),
    legend.key.height = unit(0.1, "lines"),  # Adjust this for height of individual keys
    axis.text = element_text(color = "black") # Change axis labels to be black
  )
bgd_plt

ggsave("~/Documents/GitHub/Adaptation_Observatory/response_analysis/results/response_visuals/BGD/R1/clean_data_vis/bgd_R1_targeting_map.png", plot = bgd_plt, width = 10, height = 7, dpi = 300, bg = "white")

ind_plt <- ggplot() +
  geom_sf(data = ind_sf_browser_intersect, aes(fill = "Respondents Browser Location", shape = "Respondents Browser Location"), color = "blue", size = 0.25, alpha = 0.5) + 
  geom_sf(data = ind_sf_intersect, aes(fill = "Respondents Qualtrics Location", shape = "Respondents Qualtrics Location"), color = "skyblue", size = 0.25, alpha = 0.2) + 
  geom_sf(data = ind_fb_sf_buffered, aes(fill = "Targeted Points", shape = "Targeted Points"), alpha = 1, color = NA) +
  geom_sf(data = ind_borders, aes(color = "India border", linetype = "India border"), size = 4, fill = NA, color = "black") +
  scale_fill_manual(name = "", 
                    values = c("Targeted Points" = "red", 
                               "Respondents Browser Location" = "blue", 
                               "Respondents Qualtrics Location" = "skyblue"),
                    guide = guide_legend(order = 1, nrow = 1)) +
  scale_shape_manual(name = "", 
                     values = c("Targeted Points" = 21, 
                                "Respondents Browser Location" = 21, 
                                "Respondents Qualtrics Location" = 24),
                     guide = guide_legend(order = 1, nrow = 1)) +
  scale_linetype_manual(name = "", values = c("India border" = "solid"),
                        guide = guide_legend(order = 2, nrow = 1)) +

  labs(
    title = "India R1 Spatial Targeting"
  ) +
  theme_minimal() +
  theme(
    legend.position = "bottom", 
    legend.box = "vertical", 
    plot.title = element_text(face = "bold", hjust = 0.5),
    legend.text = element_text(size = 9),
    legend.spacing.x = unit(0.25, 'cm'),
    legend.key.height = unit(0.1, "lines"),  # Adjust this for height of individual keys
    axis.text = element_text(color = "black") # Change axis labels to be black
  )
ind_plt

ggsave("~/Documents/GitHub/Adaptation_Observatory/response_analysis/results/response_visuals/IND/R1/clean_data_vis/ind_R1_targeting_map.png", plot = ind_plt, width = 10, height = 7, dpi = 300, bg = "white")

```

# Geospatial Stat. Analysis 
I want to create an object that only contains the points that overlap respondents browser location and targeted points

I then want that object to compare the number of those observations we collected in the expected regions
I want to compare the amount of success vs failure 


Leveraging the workflow Emma outlined above, I isolated regions where respondents browser location intersected with a 1km buffer around the fb ads that had been deployed.

Comparing the count of respondents within those areas to the count of fb ads that were deployed:
- BGD success rate was 41.52%
- IND success rate was 6%

One reasoning behind this discrepancy can be explained by the data limitations caused by the IND flood data. The satellite data provided by Microsoft Planetary Computer for IND was in an angled position. Regardless of the projection, it was extremely difficult getting the boundaries to align. When generating geopoints for IND, there was less confidence in the accuracy of the points being within their expected ADM1 and ADM2 boundaries. 

We deployed a large amount of ads in the NE region of IND, near BGD. Those ads did not receive a lot of feedback response. I'm curious if the ads were competing with the BGD campaign because we received a good amount of BGD income responses that were in Rupees, indicating they may be on the border / do business in IND.

Comparing the regions at risk of flood exposure to the respondents browser location that intersected. No buffers applied here.
- BGD success rate was
- IND success rate was


Confirming with the flood data, I'm really happy to see that despite the disparity in our ad success for IND, the majority of respondents for IND are located on the coast and in regions at risk to flooding. 


-- Other Updates --
Successfully translated the responses, in the process of deep cleaning the responses. I expect to have that complete by the end of this week and will use that data to generate stacked plots. I will upload those here upon completion. 

```{r ad_response_overlap}
# BGD 
# Assuming you have two spatial datasets: respondents' browser locations and targeted points
# Replace 'respondents' and 'targeted' with your actual datasets

# respondent locations inside of country boundaries
obs_in_expected_regions_bgd <- st_intersection(bgd_sf_browser_intersect, bgd_fb_sf_buffered)

# expected points 
bgd_expected_regions <- bgd_fb_sf_buffered

bgd_expected_regions


# Step 2: Count observations in expected regions
success_count <- nrow(obs_in_expected_regions_bgd)
failure_count <- nrow(bgd_expected_regions) - success_count

# Step 3: Compare success vs. failure
# Print or use the counts as needed
print(success_count)
print(failure_count)

rate_of_success_bgd <- (success_count / nrow(bgd_expected_regions)) * 100

rate_of_success_bgd






# IND 
# Assuming you have two spatial datasets: respondents' browser locations and targeted points
# Replace 'respondents' and 'targeted' with your actual datasets

# respondent locations inside of country boundaries
obs_in_expected_regions_ind <- st_intersection(ind_sf_browser_intersect, ind_fb_sf_buffered)

# expected points 
ind_expected_regions <- ind_fb_sf_buffered

#ind_expected_regions


# Step 2: Count observations in expected regions
success_count_ind <- nrow(obs_in_expected_regions_ind)
failure_count <- nrow(ind_expected_regions) - success_count_ind

# Step 3: Compare success vs. failure
# Print or use the counts as needed
print(success_count_ind)
print(failure_count)

rate_of_success_ind <- (success_count_ind / nrow(ind_expected_regions)) * 100

rate_of_success_ind
```
```{r bgd_flood_exposure_response_rate}
bgd_floods <-read_stars(here('../data/country_datas/bgd_flooding.tif')) 

# Transform the flood data into a SpatRaster object
bgd_floods_rast <- rast(bgd_floods)


# creating a mask to filter for areas at risk of experiencing flooding in 75th percentile
bgd_flood_rast <- bgd_floods_rast >= 86 

# subset 1km resolution
layer4 <- terra::subset(bgd_flood_rast, 4)


# create sf object for intersection comparision
bgd_floods_1km <- layer4 %>% 
  st_as_stars %>%
  st_as_sf() %>% 
  st_make_valid()

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#----  Set of Checks & CRS Corrections  ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# boolean test to see if resolutions match
resolution(bgd_floods_1km) == resolution(bgd_sf_browser_intersect)

st_crs(bgd_floods_1km) <- st_crs(bgd_sf_browser_intersect)

st_crs(bgd_floods_1km) == st_crs(bgd_sf_browser_intersect)


# Subset bgd_floods_1km where band4 == TRUE
# these are regions with flood exposure 
subset_floods <- bgd_floods_1km[bgd_floods_1km$`band4` == TRUE, ] %>% 
  st_make_valid()

bgd_sf_browser_intersect <- bgd_sf_browser_intersect %>% 
  st_make_valid()

# Perform intersection to find points in flood prone regions
obs_in_flood_regions_bgd <- st_intersection(bgd_sf_browser_intersect, subset_floods)

#library(foreach)
#library(doParallel)

# Set the number of cores to use
#num_cores <- detectCores()

# Initialize parallel processing
#cl <- makeCluster(num_cores)
#registerDoParallel(cl)


# Perform intersection in parallel
#obs_in_flood_regions_bgd <- foreach(i = 1:num_cores, .packages = c("sf")) %dopar% {
 # st_intersection(bgd_sf_browser_intersect, subset_floods)
#}

# Combine the results from parallel execution
#obs_in_flood_regions_bgd <- do.call(rbind, obs_in_flood_regions_bgd)

# Stop parallel processing
#stopCluster(cl)


# Step 2: Count observations in expected regions
success_flood_count_bgd <- nrow(obs_in_flood_regions_bgd)
failure_flood_count_bg <- nrow(subset_floods) - success_count_bgd

# Step 3: Compare success vs. failure
# Print or use the counts as needed
print(success_flood_count_bgd)
print(failure_flood+count_bgd)

rate_of_success_floods_bgd <- (success_flood_count_bgd / nrow(subset_floods)) * 100

rate_of_success_floods_bgd
```


```{r ind_flood_exposure_response_rate}
ind_floods <-read_stars(here('../data/country_datas/bgd_flooding5.tif')) 


# Transform the flood data into a SpatRaster object
ind_floods_rast <- rast(ind_floods)


# creating a mask to filter for areas at risk of experiencing flooding in 75th percentile
ind_flood_rast <- ind_floods_rast >= 86 

# subset 1km resolution
layer4 <- terra::subset(ind_flood_rast, 4)

ind_floods_sf<- ind_floods  %>% 
  st_as_stars() %>% 
  st_as_sf() %>% 
  st_make_valid() 


# select 1km resolution from tiff:vector data
ind_flood_1km_sf <- ind_floods_sf %>% dplyr::select(ind_flooding5.tif.V4) 

#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
#----  Set of Checks & CRS Corrections  ----
#~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
# boolean test to see if resolutions match
resolution(ind_floods_1km_sf) == resolution(ind_sf_browser_intersect)

st_crs(ind_floods_1km_sf) <- st_crs(ind_sf_browser_intersect)

st_crs(ind_floods_1km_sf) == st_crs(ind_sf_browser_intersect)


# Subset bgd_floods_1km where band4 == TRUE
# these are regions with flood exposure 
subset_floods <- ind_floods_1km[ind_flood_1km$`band4` == TRUE, ] %>% 
  st_make_valid()


# Perform intersection to find points in flood prone regions
obs_in_flood_regions_ind <- st_intersection(ind_sf_browser_intersect, subset_floods)


# Step 2: Count observations in expected regions
success_count_ind <- nrow(obs_in_flood_regions_ind)
failure_count <- nrow(subset_floods) - success_count_ind

# Step 3: Compare success vs. failure
# Print or use the counts as needed
print(success_flood_count_ind)
print(failure_flood+count_ind)

rate_of_success_floods_ind <- (success_flood_count_ind / nrow(subset_floods)) * 100

rate_of_success_floods_ind

```


```{r}
```


```{r}
```



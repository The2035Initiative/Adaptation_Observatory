---
author: "Sofia Ingersoll"
title: "Adaptation Observatory: Function to Read & Wrangle Survey Responses"
date: 2024-4-14
format:
  html:
    code-fold: true
    code-summary: "Show the code"
#embed-resources: true
---

## Set Up

```{r message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

#..........................load packages.........................
library(tidyverse)        
library(here)
```

## Function to Read & Wrangle Response Demographic Data
```{r}
read_n_wrangle_data <- function(file_path) {
  # Read data
  responses <- read_csv(file_path, show_col_types = FALSE)
  
  # Select and clean columns
  demos <- responses %>%
    dplyr::select(IPAddress, age, gender, region, LocationLatitude, LocationLongitude, demo_age, demo_gender,
                   # Impact of floods
                  flood_year, housing_damage, property_loss, contact_authority, flood_close,
                   # Socioeconomic factors & resiliency / scarcity 
                  stay_residence, flood_prepared, housing_safe, enough_eat, move_rural_urban, demo_income, 
                   # Sentiments 
                  climate_problem, trust_government) %>%
    janitor::clean_names() %>%
    mutate(location_longitude = as.numeric(location_longitude),
           location_latitude = as.numeric(location_longitude)) %>%
    # Remove incomplete geolocations
    filter(complete.cases(location_latitude, location_longitude)) %>% 
  # Remove rows with missing or non-numeric longitude or latitude values
    filter(!is.na(location_longitude) & !is.na(location_latitude))
  
  # Remove first two rows
  demos <- demos[-c(1, 2), ]
  
  return(demos)
}


# Load and wrangle Bangladesh data
bgd_demos <- read_n_wrangle_data(here("..", "data", "adapt_observ_survey_responses", "Observatory_Bangladesh_2024_04_15.csv"))
bgd_demos
```

## Load Data
```{r}
bgd_responses <- read_csv(here("..","data","adapt_observ_survey_responses", "Observatory_Bangladesh_2024_04_15.csv"), show_col_types = FALSE)
```

## Wrangle Data
```{r}
#head(bgd_responses)
#str(bgd_responses)
# to create a list of variables to subset
#colnames(bgd_responses)

# to get an idea of how many unique observations we have
# the length is 3515, therefore our dataset of 4699 contains repeating observations
# we'll use IPAddress to isolate unique participants 
# it's safe to double check these entrees with the age + gender columns to make sure multiple family members that are logging in from the same IPAddress aren't missed
length(unique(bgd_responses$IPAddress))
length(unique(bgd_responses$age))
length(unique(bgd_responses$gender))
length(unique(bgd_responses$region))
```

```{r}
# these lines are grouped by demographics of interest
  # top line relates to personal demographics
bgd_demos <- bgd_responses %>%
  dplyr::select(IPAddress, age, gender, region, LocationLatitude, LocationLongitude, demo_age, demo_gender,
                 # impact of floods
                flood_year, housing_damage, property_loss, contact_authority, flood_close,
                 # socioeconomic factors & resiliency / scarcity 
                stay_residence, flood_prepared, housing_safe, enough_eat, move_rural_urban, demo_income, 
                # sentiments 
                climate_problem, trust_government) %>%
  janitor::clean_names() %>%
  mutate(location_longitude = as.numeric(location_longitude),
         location_latitude = as.numeric(location_latitude)) %>%
  # remove incomplete geolocations
  filter(complete.cases(location_latitude, location_longitude))
 
         
# remove first two rows
bgd_demos <- bgd_demos[-c(1,2), ]

bgd_demos
```

### Exploring Duplicates
```{r}
# let's filter ip address that have responded more than once
# 1031 ip addressses appeared more than once
repeated_ip_addr <- bgd_demos %>%
  group_by(ip_address) %>%
  filter(n() > 1)

repeated_ip_addr

# now let's collect the different responses of those ip addresses
# we expect a many to many relationship between these df 
# 3957 responses were pulled from the repeating ip addr
#multiple_responses <- semi_join(bgd_demos, repeated_ip_addr, by = "ip_address") 

multiple_responses <- inner_join(bgd_demos, repeated_ip_addr, by = "ip_address") 


# Select columns to pivot (excluding ip_address)
cols_to_pivot <- setdiff(names(multiple_responses), "ip_address")

# Pivot selected columns into long format
multiple_responses <- multiple_responses %>%
  #
  pivot_longer(cols = all_of(cols_to_pivot), 
               # store x and y in a new column called variable
               names_to = c(".value", "variable"), 
               # use the . in the colname to separate unwanted the characters 
               names_sep = "\\.") %>% 
  # remove duplicate entrees that were created using pivot_longer()
  filter(!grepl("y", variable)) %>% 
  # remove extra column
  dplyr::select(-'variable')

multiple_responses
```


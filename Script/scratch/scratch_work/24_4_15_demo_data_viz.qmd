---
author: "Sofia Ingersoll"
title: "Adaptation Observatory: Survey Response Demographics (Bangladesh & India)"
date: 2024-4-14
format:
  html:
    code-fold: true
    code-summary: "Show the code"
#embed-resources: true
---
```{r read_n_wrangle_data, message = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)

#..........................load packages.........................
library(tidyverse)        # load the tidyverse package to assist with data wrangling & cleaning 

library(patchwork)        # load the patchwork package to assist in plot composition (displaying multiple data visualizations) 

library(showtext)         # load the showtext to more easily use fonts
library(here)

library(leaflet)
library(osmextract) 
library(units)
library(sf)
library(sfheaders)
library(sp)
library(raster)
library(tmap)
library(terra)
library(stars)
library(ggtext)
library(units)

library(tidyverse)
library(treemap)
library(sunburstR)
library(purrr)

# load data
bgd_file <- file.path(here("..","data","adapt_observ_survey_responses", "Observatory_Bangladesh_2024_04_15.csv"))
  
ind_file <- file.path(here("..","data","adapt_observ_survey_responses", "Observatory_India_2024_04_15.csv"))

bgd_responses <- read_csv(bgd_file, show_col_types = FALSE)
  
ind_responses <-read_csv(ind_file, show_col_types = FALSE)


bgd_demos <- bgd_responses %>%
  dplyr::select(IPAddress, age, gender, region, LocationLatitude, LocationLongitude, demo_age, demo_gender,
                 # impact of floods
                flood_year, housing_damage, property_loss, contact_authority, flood_close,
                 # socioeconomic factors & resiliency / scarcity 
                stay_residence, flood_prepared, housing_safe, enough_eat, move_rural_urban, demo_income, 
                # sentiments 
                climate_problem, trust_government) %>%
  
  janitor::clean_names() %>%
  
  # Treat NA as a separate category
  mutate(across(where(is.character), ~ifelse(. %in% c(NA, "NA"), "Not Disclosed", .)),
         across(where(is.numeric), ~ifelse(is.na(.), "Not Disclosed", .))) %>% 
  
  mutate(location_longitude = as.numeric(location_longitude),
         location_latitude = as.numeric(location_latitude)) %>%
  # remove incomplete geolocations
  filter(complete.cases(location_latitude, location_longitude)) %>% 
  # Count the occurrences of each IPAddress
  group_by(ip_address) %>%
  mutate(number_of_surverys_submitted = n()) %>%
  ungroup() %>%
  # remove first two rows
  slice(-c(1, 2))
 

ind_demos <- ind_responses %>%
  dplyr::select(IPAddress, age, gender, region, LocationLatitude, LocationLongitude, demo_age, demo_gender,
                 # impact of floods
                flood_year, housing_damage, property_loss, contact_authority, flood_close,
                 # socioeconomic factors & resiliency / scarcity 
                stay_residence, flood_prepared, housing_safe, enough_eat, move_rural_urban, demo_income, 
                # sentiments 
                climate_problem, trust_government) %>%
  
  janitor::clean_names() %>%
  
  # Treat NA as a separate category
  mutate(across(where(is.character), ~ifelse(. %in% c(NA, "NA"), "Not Disclosed", .)),
         across(where(is.numeric), ~ifelse(is.na(.), "Not Disclosed", .))) %>% 
  
  mutate(location_longitude = as.numeric(location_longitude),
         location_latitude = as.numeric(location_latitude)) %>%
  # remove incomplete geolocations
  filter(complete.cases(location_latitude, location_longitude)) %>% 
  # Count the occurrences of each IPAddress
  group_by(ip_address) %>%
  mutate(number_of_surverys_submitted = n()) %>%
  ungroup() %>%
  # remove first two rows
  slice(-c(1, 2))


# map data
bgd_demo_sf <- bgd_demos %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326")


ind_demo_sf <- ind_demos %>% 
  st_as_sf(coords = c("location_longitude", "location_latitude"), crs = "EPSG:4326")
```
# Overview

BGD has ~4x the amount of duplicate survey responses compared to duplicate ip addresses

# How many duplicate ip addresses?

## BGD: 1031
## IND: 62

# How many surveys from duplicate ip addresses?

## BGD: 3957
## IND: 124

# What's the most number of surveys a single ip address has submitted?
## BGD: 22
## IND: 2

```{r duplicate_ip_addr}
## BGD
# let's filter ip address that have responded more than once
# 1031 ip addressses appeared more than once
bgd_repeated_ip_addr <- bgd_demos %>%
  group_by(ip_address) %>%
  filter(n() > 1)

bgd_repeated_ip_addr

# now let's collect the different responses of those ip addresses
# we expect a many to many relationship between these df 
# 3957 responses were pulled from the repeating ip addr
#multiple_responses <- semi_join(bgd_demos, repeated_ip_addr, by = "ip_address") 

bgd_multiple_responses <- inner_join(bgd_demos, bgd_repeated_ip_addr, by = "ip_address") 


# Select columns to pivot (excluding ip_address)
cols_to_pivot <- setdiff(names(bgd_multiple_responses), "ip_address")

# Pivot selected columns into long format
bgd_multiple_responses <- bgd_multiple_responses %>%
  #
  pivot_longer(cols = all_of(cols_to_pivot), 
               # store x and y in a new column called variable
               names_to = c(".value", "variable"), 
               # use the . in the colname to separate unwanted the characters 
               names_sep = "\\.") %>% 
  # remove duplicate entrees that were created using pivot_longer()
  filter(!grepl("y", variable)) %>% 
  # remove extra column
  dplyr::select(-'variable')

count(bgd_multiple_responses)


## INDIA
# let's filter ip address that have responded more than once
# 62 ip addressses appeared more than once
ind_repeated_ip_addr <- ind_demos %>%
  group_by(ip_address) %>%
  filter(n() > 1)

ind_repeated_ip_addr

# now let's collect the different responses of those ip addresses
# we expect a many to many relationship between these df 
# 124 responses were pulled from the repeating ip addr
#multiple_responses <- semi_join(bgd_demos, repeated_ip_addr, by = "ip_address") 

ind_multiple_responses <- inner_join(ind_demos, ind_repeated_ip_addr, by = "ip_address") 


# Select columns to pivot (excluding ip_address)
cols_to_pivot <- setdiff(names(ind_multiple_responses), "ip_address")

# Pivot selected columns into long format
ind_multiple_responses <- ind_multiple_responses %>%
  #
  pivot_longer(cols = all_of(cols_to_pivot), 
               # store x and y in a new column called variable
               names_to = c(".value", "variable"), 
               # use the . in the colname to separate unwanted the characters 
               names_sep = "\\.") %>% 
  # remove duplicate entrees that were created using pivot_longer()
  filter(!grepl("y", variable)) %>% 
  # remove extra column
  dplyr::select(-'variable')

count(ind_multiple_responses)
```

```{r max_duplicate}
# let's check our new column
max(bgd_demos$number_of_surverys_submitted)

max(ind_demos$number_of_surverys_submitted)
```
# Where are the surveys submitted geographically?

consideration: ip_adddress * geometry

## BGD:
```{r bgd_map}
tmap_mode('view')

bgd_response_map <- tm_shape(bgd_demo_sf) +
  tm_basemap(leaflet::providers$Esri.WorldImagery) +
  tm_bubbles(alpha = 0.2,
             fill = 'ip_address',
             col = 'skyblue',) +
  tm_scalebar(position = c('left', 'bottom')) +
  tm_title("Adaptation Observatory Responses, Bangladesh (2024-4-15)")


bgd_response_map
```

## IND:
```{r ind_map}
tmap_mode('view')

ind_response_map <- tm_shape(ind_demo_sf) +
  tm_basemap(leaflet::providers$Esri.WorldImagery) +
  tm_bubbles(alpha = 0.2,
             fill = 'ip_address',
             col = 'skyblue',) +
  tm_scalebar(position = c('left', 'bottom')) +
  tm_title("Adaptation Observatory Responses, Bangladesh (2024-4-15)")

ind_response_map
```

# What are the summary stats of each attribute?

## BGD:

# What are the summarry stats of the attributes?
Majority Responders are:
- Not Disclosed, Female, 
- Not Disclosed, 50 is the most common age


Flood Exposure:
- Flood year: not disclosed, yes
- Housing Damage: no, yes
- Property Loss: no, yes
- Flood Close:  yes, not disclosed  *only difference from India stats*

Resilience & Scarcity:
- Contact Authority: not disclosed, yes
- Stay residence: no, yes
- Enough to eat: not disclosed, no
- Move rural urban: not disclosed, no
```{r bgd_summary}
# Select the index columns from your data
index_columns <- c("region", "gender", "age", "flood_year", "housing_damage", "property_loss", 
                   "contact_authority", "flood_close", "stay_residence", "flood_prepared", 
                   "housing_safe", "enough_eat", "move_rural_urban", "demo_income", 
                   "climate_problem", "trust_government")

# Initialize an empty list to store the summaries
bgd_summary_list <- list()

# Iterate over each index column
for (column in index_columns) {
  # Group the data by the index column and summarize the counts of each response type
  summary <- bgd_demos %>%
    group_by(!!sym(column)) %>%
    summarise(
      Yes = sum(. == "Yes" | . == "yes"),
      No = sum(. == "No" | . == "no"),
      `Not Disclosed` = sum(is.na(.) | . == "Not Disclosed"),
      Total = n()  # Total count of responses in the group
    ) %>%
    ungroup() %>%
    # Normalize the counts to proportions
    mutate(
      Yes = Yes / Total,
      No = No / Total,
      `Not Disclosed` = `Not Disclosed` / Total
    ) %>%
    dplyr::select(-Total)  # Remove the Total column after normalization
  
  # Store the summary in the list
  bgd_summary_list[[column]] <- summary
}

# Access the normalized summaries for each index column
bgd_summary_list
```

Self declared men in not disclosed:
pacakge datamaid : load data set 

Moving forward:
*subset people who have provided a phone number* those without phone # are never to be in panel
Emma lsit of response IDs: index to subset

histogram of basic distribution of demographics
people who give location vs done: how are they different
how are the location and ip_address & phone numbers same or different
do this for duplicate subset

Explicit test of wht fraction of locations are located within the spatial polygon we were sampling

within 5-10km buffer potentially as a result of cell-towers

How affective have we been finding indiividuals we hoped to find in these areas

validate & quanitfy % accuracy
from that sample: assess group representation benchmarks
(gender, income, age) start with this for now

curious about 
distribution of languages people took the survey in (11 regional languages, qualtrix recorded the type as a metric)

We expect people falling within validated bufffers to report seeing a flood more often or experience a negative experience more often than those outside of our AOI.

Considerations moving forward
- who's inside and outside AOI || DROP 
- who among the respondents are most likely to contribute to the panel moving forward


## IND:

# What are the summarry stats of the attributes?
Majority Responders are:
- Not Disclosed, then Female, 
- Not Disclosed, 50 is the most common age


Flood Exposure:
- Flood year: not disclosed, yes
- Housing Damage: no, yes
- Property Loss: no, yes
- Flood Close: yes, no

Resilience & Scarcity:
- Contact Authority: not disclosed, yes
- Stay residence: no, yes
- Enough to eat: not disclosed, no
- Move rural urban: not disclosed, no


```{r ind_summary}
# Select the index columns from your data
index_columns <- c("region", "gender", "age", "flood_year", "housing_damage", "property_loss", 
                   "contact_authority", "flood_close", "stay_residence", "flood_prepared", 
                   "housing_safe", "enough_eat", "move_rural_urban", "demo_income", 
                   "climate_problem", "trust_government")

# Initialize an empty list to store the summaries
ind_summary_list <- list()

# Iterate over each index column
for (column in index_columns) {
  # Group the data by the index column and summarize the counts of each response type
  summary <- bgd_demos %>%
    group_by(!!sym(column)) %>%
    summarise(
      Yes = sum(. == "Yes" | . == "yes"),
      No = sum(. == "No" | . == "no"),
      `Not Disclosed` = sum(is.na(.) | . == "Not Disclosed"),
      Total = n()  # Total count of responses in the group
    ) %>%
    ungroup() %>%
    # Normalize the counts to proportions
    mutate(
      Yes = Yes / Total,
      No = No / Total,
      `Not Disclosed` = `Not Disclosed` / Total
    ) %>%
    dplyr::select(-Total)  # Remove the Total column after normalization
  
  # Store the summary in the list
  ind_summary_list[[column]] <- summary
}

# Access the normalized summaries for each index column
ind_summary_list
```


# What are the overall trends in the demographics?
```{r treemap_func, fig.height=11, fig.width=22}
# tree map function
generate_treemap_plots <- function(data, country, parameter) {
  # Create the output folder based on the country name
 # output_folder <- paste0("plots_", gsub(" ", "_", tolower(country)))
  #if (!dir.exists(output_folder)) {
   # dir.create(output_folder)
  #}
  
  
  # Define a color palette
  #colors <-   colorRampPalette(rev(brewer.pal(11, "Set3")))(50)
  colors <- rev(brewer.pal(11, 'Set3'))

  
  # Create a list to store the plots
  plots <- list()
  
  # Iterate through the parameters
  for (param in parameter) {
    # Create the treemap
    plot <- treemap(data,
                    index = c("region", "gender", "age", param),
                    vSize = "number_of_surveys_submitted",
                    algorithm = "squarified",
                    title = paste(str_to_title(country), "Survey Response:", str_to_title(gsub("_", " ", param)), "by Region, Gender, and Age"),
                    palette = colors,
                    
                    # Increase the font size of the title
                    fontsize.title = 50,   
                    
                    # Set title typeface
                    fontfamily.title = "josefin",
                    
                    # Font size for labels
                    fontsize.labels = c(40, 25, 20, 18),  
                    
                    # Set text color to white for all levels
                    fontcolor.labels = c("black", "grey20", "white"), 
                    
                    fontfamily.labels = c("josefin","sen","sen","sen"),  # Font family for labels
        
                    # Bold the parameter label
                    fontface.labels = c("bold", "plain", "bold", "bold"),  
                    
                    # Set border color to white for better visibility
                    border.col = "white", 
                   
                    # Adjust line size (border width) as needed 
                    border.lw = 2,  
                    
                    # Align labels to center
                    align.labels = list(c("center", "center", "center", "center")), 
                    
                    # Adjust overlap for better readability
                    overlap.labels = 0,  
                    
                    # Set background color of labels to transparent
                    #bg.labels = "transparent", 
                    
                    # Add a margin (top, right, bottom, left)
                    margin = c(20, 20, 20, 20), 
                    
                    # Font size for background labels
                    fontsize.labels.bg = c(16, 14),
                    
                    # Specify the width of the plot
                    width = 1920,  
                    
                    # Specify the height of the plot
                    # Adjust the height proportionally (e.g., 75% of the width)
                    height = 1920 * 0.75  
                  
    ) 
    
    # Save the plot as a PNG file in the output folder
  #  filename <- file.path(output_folder, paste0(param, ".png"))
   # ggsave(filename, plot, width = 12, height = 8)  # Adjust width and height as needed
    
    # Append the plot to the list
    plots[[param]] <- plot
  }
  
  return(plots)
}

# Define the parameters to iterate through
parameters <- c("flood_year", "housing_damage", "property_loss", "contact_authority", "flood_close", 
                "flood_prepared", "stay_residence", "enough_eat", "move_rural_urban", "demo_income",
                'demo_gender',"demo_age")
```

```{r bgd_wrangle}
# tree map data
cols_to_calc <- c('flood_year', 'housing_damage', 'property_loss', 'contact_authority', 'flood_close', 'flood_prepared',
           'stay_residence', 'enough_eat', 'move_rural_urban', 'demo_income')

# Grouping the data by region
grouped_data <- bgd_demos %>%
  group_by(region) %>%
  mutate(across(
    .cols = all_of(cols_to_calc),
    .fns = list(
      Yes = ~ mean(. %in% c("Yes", "yes")),
      No = ~ mean(. %in% c("No", "no")),
      `Not Disclosed` = ~ mean(is.na(.) | . == "Not Disclosed")
    ),
    .names = "{.col}_{.fn}"
  )) %>%
  ungroup()

# Now, group by all variables including region
grouped_data <- grouped_data %>%
  group_by(region, gender, demo_gender, age, demo_age, flood_year, housing_damage, property_loss, contact_authority, flood_close, flood_prepared,
           stay_residence, enough_eat, move_rural_urban, demo_income) %>%
  summarise(number_of_surveys_submitted = n()) %>%
  ungroup()
```


## BGD:
```{r bgd_treemaps, fig.height=11, fig.width=22}
# Generate treemap plots for each parameter
plots_collection <- generate_treemap_plots(data = grouped_data,
                                           country = "BGD", 
                                           parameter = parameters)
```

## IND:
```{r ind_wrangle}
# tree map data
cols_to_calc <- c('flood_year', 'housing_damage', 'property_loss', 'contact_authority', 'flood_close', 'flood_prepared',
           'stay_residence', 'enough_eat', 'move_rural_urban', 'demo_income')

# Grouping the data by region
grouped_data <- bgd_demos %>%
  group_by(region) %>%
  mutate(across(
    .cols = all_of(cols_to_calc),
    .fns = list(
      Yes = ~ mean(. %in% c("Yes", "yes")),
      No = ~ mean(. %in% c("No", "no")),
      `Not Disclosed` = ~ mean(is.na(.) | . == "Not Disclosed")
    ),
    .names = "{.col}_{.fn}"
  )) %>%
  ungroup()

# Now, group by all variables including region
grouped_data <- grouped_data %>%
  group_by(region, gender, demo_gender, age, demo_age, flood_year, housing_damage, property_loss, contact_authority, flood_close, flood_prepared,
           stay_residence, enough_eat, move_rural_urban, demo_income) %>%
  summarise(number_of_surveys_submitted = n()) %>%
  ungroup()
```


```{r ind_treemaps, fig.height=11, fig.width=22}
# Generate treemap plots for each parameter
plots_collection <- generate_treemap_plots(data = grouped_data,
                                           country = "India", 
                                           parameter = parameters)
```

